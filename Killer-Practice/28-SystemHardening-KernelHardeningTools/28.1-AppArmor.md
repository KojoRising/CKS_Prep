# PRACTICE/OVERVIEW
```yaml
curl https://raw.githubusercontent.com/KojoRising/CKA_Prep/main/abbreviated_alias.sh > alias.sh && source alias.sh
```

## 1 Check existing AppArmor profiles
You're asked to verify if the following AppArmor profiles are available on node01 :

docker-default
snap.lxd.lxc
ftpd
/usr/sbin/tcpdump

Create file /root/profiles.txt on node controlplane . It should contain only these profile names that are available on node01 .



#### 1)
```yaml
node01 $ vi my-profiles
node01 $ aa-status | grep -f my-profiles 
   /usr/sbin/tcpdump
   docker-default
   snap.lxd.lxc
   snap.lxd.lxc-to-lxd
```

## 2 Fix Deployment with wrong AppArmor config
There is an existing Deployment named spacecow in Namespace moon .
It should be configured to use AppArmor profile docker-default , but something seems wrong.

#### 2) Initial deployment
```yaml
controlplane $ kubens moon
Context "kubernetes-admin@kubernetes" modified.
moon
controlplane $ kg deploy/spacecow -oyaml | tee spacecow.yaml
## Original Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    container.apparmor.security.beta.kubernetes.io/httpd: localhost/docker-default
    deployment.kubernetes.io/revision: "1"
  name: spacecow
  namespace: moon
spec:
  progressDeadlineSeconds: 600
  replicas: 3
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: spacecow
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      annotations:
        container.apparmor.security.beta.kubernetes.io/httpd: localhost/docker-default
      labels:
        app: spacecow
    spec:
      containers:
      - image: httpd:2.4.52-alpine
        imagePullPolicy: IfNotPresent
        name: httpd
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30

## Fixed deployment - Need to annotate pod-level and fix label-key's container name
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    container.apparmor.security.beta.kubernetes.io/httpd: localhost/docker-default
    deployment.kubernetes.io/revision: "1"
  name: spacecow
  namespace: moon
spec:
  progressDeadlineSeconds: 600
  replicas: 3
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: spacecow
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      annotations:
        container.apparmor.security.beta.kubernetes.io/httpd: localhost/docker-default
      labels:
        app: spacecow
    spec:
      containers:
      - image: httpd:2.4.52-alpine
        imagePullPolicy: IfNotPresent
        name: httpd
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
```
## 3 Install AppArmor profile on nodes
- There is an AppArmor profile at /root/profile .
- It should be referenced by name docker-nginx-custom , change the profile if needed.
- Install it on nodes controlplane and node01 .

#### 3)  Use `apparmor_parser` to load onto nodes
```yaml
## Load Onto Controlplane
controlplane $ aa-status | grep docker-nginx
controlplane $ apparmor_parser profile
controlplane $ aa-status | grep docker-nginx 
   docker-nginx-custom

## Load Onto Node01
node01 $ aa-status | grep docker-nginx
node01 $ apparmor_parser profile
node01 $ aa-status | grep docker-nginx
  docker-nginx-custom
```
